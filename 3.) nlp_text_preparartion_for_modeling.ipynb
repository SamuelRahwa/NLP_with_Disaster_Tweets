{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd091f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:22:53.686879Z",
     "start_time": "2022-07-11T22:22:53.683729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bag Of Words:\n",
    "\n",
    "# We define a fixed length vector where each entry corresponds to a word in our pre-defined dictionary of words. The size of the vector equals the size of the dictionary. \n",
    "# Then, for representing a text using this vector, we count how many times each word of our dictionary appears in the text and we put this number in the corresponding vector entry.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tf-IDF:\n",
    "\n",
    "# Term frequency-inverse document frequency (TF-IDF) gives a measure that takes the importance of a word into consideration depending on how frequently it occurs in a document and a corpus.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Word to Vector:\n",
    "\n",
    "# Converting words to vectors, or word vectorization, is a natural language processing (NLP) process. \n",
    "# The process uses language models to map words into vector space. A vector space represents each word by a vector of real numbers. It also allows words with similar meanings have similar representations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Count Vectorizer: \n",
    "\n",
    "# It will fit and learn the word vocabulary and try to create a document term matrix in which the individual cells denote the frequency of that word in a particular document, which is also known as term frequency, and the columns are dedicated to each word in the corpus.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transfer Learning:\n",
    "\n",
    "# It uses a prebuilt model on your data and gives pretty good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5483f46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:22:54.006193Z",
     "start_time": "2022-07-11T22:22:54.003700Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9960b56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:07.166339Z",
     "start_time": "2022-07-11T22:22:54.246636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Nel-\n",
      "[nltk_data]     Jiren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Nel-Jiren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nel-\n",
      "[nltk_data]     Jiren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# For Plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "matplotlib.rcParams['figure.figsize'] = (22,10)\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "import seaborn as sns \n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# For processing\n",
    "import re, string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing, feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "# For explainer\n",
    "#from lime import lime_text\n",
    "\n",
    "# For word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "# For deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# For bert language model\n",
    "#import transformers\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a2f84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:48.122427Z",
     "start_time": "2022-07-11T22:23:48.041040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7503 entries, 0 to 7502\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   keyword                    7447 non-null   object \n",
      " 1   location                   5021 non-null   object \n",
      " 2   text                       7503 non-null   object \n",
      " 3   target                     7503 non-null   int64  \n",
      " 4   total_words                7503 non-null   int64  \n",
      " 5   char_count                 7503 non-null   int64  \n",
      " 6   sentence_count             7503 non-null   int64  \n",
      " 7   avg_word_length            7503 non-null   float64\n",
      " 8   avg_sentence_lenght        7503 non-null   float64\n",
      " 9   tokenized_text             7503 non-null   object \n",
      " 10  clean_text                 7460 non-null   object \n",
      " 11  clean_total_words          7503 non-null   int64  \n",
      " 12  clean_char_count           7503 non-null   int64  \n",
      " 13  clean_sentence_count       7503 non-null   int64  \n",
      " 14  clean_avg_word_length      7503 non-null   float64\n",
      " 15  clean_avg_sentence_lenght  7503 non-null   float64\n",
      "dtypes: float64(4), int64(7), object(5)\n",
      "memory usage: 938.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# importing dataset\n",
    "\n",
    "data = pd.read_csv('preprocessed_clean_train_set.csv') \n",
    "\n",
    "\n",
    "# Reviewing the data shape, columns and data types\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877cbb3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:48.426482Z",
     "start_time": "2022-07-11T22:23:48.380788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Missing Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>2482</td>\n",
       "      <td>33.080101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <td>56</td>\n",
       "      <td>0.746368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_text</th>\n",
       "      <td>43</td>\n",
       "      <td>0.573104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total  Missing Percent\n",
       "location     2482        33.080101\n",
       "keyword        56         0.746368\n",
       "clean_text     43         0.573104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of Data Missing Per Column Above 1%\n",
    "\n",
    "total = data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Missing Percent'])\n",
    "missing_data['Missing Percent'] = missing_data['Missing Percent'].apply(lambda x: x * 100)\n",
    "missing_data.loc[missing_data['Missing Percent'] > .01][:152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719047a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:49.065947Z",
     "start_time": "2022-07-11T22:23:49.036028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>total_words</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_lenght</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_total_words</th>\n",
       "      <th>clean_char_count</th>\n",
       "      <th>clean_sentence_count</th>\n",
       "      <th>clean_avg_word_length</th>\n",
       "      <th>clean_avg_sentence_lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>['this', 'is', 'ridiculous', '...']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['LOOOOOOL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>???? it was an accident http://t.co/Oia5fxi4gM</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['?', '?', '?', 'it', 'was', 'an', 'accident',...</td>\n",
       "      <td>accident</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>accident</td>\n",
       "      <td>Alberta | Sask. | Montana</td>\n",
       "      <td>Suffield Alberta Accident https://t.co/bPTmlF4P10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['Suffield', 'Alberta', 'Accident', 'https://t...</td>\n",
       "      <td>accident</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>accident</td>\n",
       "      <td>Gloucestershire , UK</td>\n",
       "      <td>@flowri were you marinading it or was it an ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['@flowri', 'were', 'you', 'marinading', 'it',...</td>\n",
       "      <td>accident</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#??? #?? #??? #??? MH370: Aircraft debris foun...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>3.6</td>\n",
       "      <td>['#', '?', '?', '?', '#', '?', '?', '#', '?', ...</td>\n",
       "      <td>aircraft debris find la reunion miss malaysia ...</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#breaking #LA Refugio oil spill may have been ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>6.5</td>\n",
       "      <td>['#breaking', '#LA', 'Refugio', 'oil', 'spill'...</td>\n",
       "      <td>refugio oil spill costlier big project</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>6.210526</td>\n",
       "      <td>3.8</td>\n",
       "      <td>['#WorldNews', 'Fallen', 'powerlines', 'on', '...</td>\n",
       "      <td>fall pipeline link tram update fire crew evacu...</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>5.5</td>\n",
       "      <td>['Two', 'giant', 'cranes', 'holding', 'a', 'br...</td>\n",
       "      <td>giant crane hold bridge collapse nearby home</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>6.307692</td>\n",
       "      <td>6.5</td>\n",
       "      <td>['The', 'Latest', ':', 'More', 'Homes', 'Razed...</td>\n",
       "      <td>late home raze northern california wildfire ac...</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword                   location  \\\n",
       "20         NaN                        NaN   \n",
       "24         NaN                        NaN   \n",
       "89    accident                        NaN   \n",
       "93    accident  Alberta | Sask. | Montana   \n",
       "97    accident       Gloucestershire , UK   \n",
       "...        ...                        ...   \n",
       "7492       NaN                        NaN   \n",
       "7495       NaN                        NaN   \n",
       "7498       NaN                        NaN   \n",
       "7501       NaN                        NaN   \n",
       "7502       NaN                        NaN   \n",
       "\n",
       "                                                   text  target  total_words  \\\n",
       "20                               this is ridiculous....       0            3   \n",
       "24                                             LOOOOOOL       0            1   \n",
       "89       ???? it was an accident http://t.co/Oia5fxi4gM       0            6   \n",
       "93    Suffield Alberta Accident https://t.co/bPTmlF4P10       1            4   \n",
       "97    @flowri were you marinading it or was it an ac...       0           10   \n",
       "...                                                 ...     ...          ...   \n",
       "7492  #??? #?? #??? #??? MH370: Aircraft debris foun...       1           18   \n",
       "7495  #breaking #LA Refugio oil spill may have been ...       1           13   \n",
       "7498  #WorldNews Fallen powerlines on G:link tram: U...       1           19   \n",
       "7501  Two giant cranes holding a bridge collapse int...       1           11   \n",
       "7502  The Latest: More Homes Razed by Northern Calif...       1           13   \n",
       "\n",
       "      char_count  sentence_count  avg_word_length  avg_sentence_lenght  \\\n",
       "20            20               5         6.666667                  0.6   \n",
       "24             8               1         8.000000                  1.0   \n",
       "89            41               2         6.833333                  3.0   \n",
       "93            46               2        11.500000                  2.0   \n",
       "97            44               1         4.400000                 10.0   \n",
       "...          ...             ...              ...                  ...   \n",
       "7492         105               5         5.833333                  3.6   \n",
       "7495          87               2         6.692308                  6.5   \n",
       "7498         118               5         6.210526                  3.8   \n",
       "7501          73               2         6.636364                  5.5   \n",
       "7502          82               2         6.307692                  6.5   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "20                  ['this', 'is', 'ridiculous', '...']   \n",
       "24                                         ['LOOOOOOL']   \n",
       "89    ['?', '?', '?', 'it', 'was', 'an', 'accident',...   \n",
       "93    ['Suffield', 'Alberta', 'Accident', 'https://t...   \n",
       "97    ['@flowri', 'were', 'you', 'marinading', 'it',...   \n",
       "...                                                 ...   \n",
       "7492  ['#', '?', '?', '?', '#', '?', '?', '#', '?', ...   \n",
       "7495  ['#breaking', '#LA', 'Refugio', 'oil', 'spill'...   \n",
       "7498  ['#WorldNews', 'Fallen', 'powerlines', 'on', '...   \n",
       "7501  ['Two', 'giant', 'cranes', 'holding', 'a', 'br...   \n",
       "7502  ['The', 'Latest', ':', 'More', 'Homes', 'Razed...   \n",
       "\n",
       "                                             clean_text  clean_total_words  \\\n",
       "20                                                  NaN                  1   \n",
       "24                                                  NaN                  1   \n",
       "89                                             accident                  1   \n",
       "93                                             accident                  1   \n",
       "97                                             accident                  1   \n",
       "...                                                 ...                ...   \n",
       "7492  aircraft debris find la reunion miss malaysia ...                  8   \n",
       "7495             refugio oil spill costlier big project                  6   \n",
       "7498  fall pipeline link tram update fire crew evacu...                  9   \n",
       "7501       giant crane hold bridge collapse nearby home                  7   \n",
       "7502  late home raze northern california wildfire ac...                  8   \n",
       "\n",
       "      clean_char_count  clean_sentence_count  clean_avg_word_length  \\\n",
       "20                   0                     1               0.000000   \n",
       "24                   0                     1               0.000000   \n",
       "89                   8                     1               8.000000   \n",
       "93                   8                     1               8.000000   \n",
       "97                   8                     1               8.000000   \n",
       "...                ...                   ...                    ...   \n",
       "7492                47                     1               5.875000   \n",
       "7495                33                     1               5.500000   \n",
       "7498                51                     1               5.666667   \n",
       "7501                38                     1               5.428571   \n",
       "7502                45                     1               5.625000   \n",
       "\n",
       "      clean_avg_sentence_lenght  \n",
       "20                          1.0  \n",
       "24                          1.0  \n",
       "89                          1.0  \n",
       "93                          1.0  \n",
       "97                          1.0  \n",
       "...                         ...  \n",
       "7492                        8.0  \n",
       "7495                        6.0  \n",
       "7498                        9.0  \n",
       "7501                        7.0  \n",
       "7502                        8.0  \n",
       "\n",
       "[1075 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Duplicates \n",
    "\n",
    "data[data.duplicated(subset = \"clean_text\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95b132f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:52.343083Z",
     "start_time": "2022-07-11T22:23:52.336946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping Rows with any missing values\n",
    "\n",
    "data.dropna(axis = 0, subset = ['clean_text'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c8efee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:52.738427Z",
     "start_time": "2022-07-11T22:23:52.715560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Missing Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>2458</td>\n",
       "      <td>32.949062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <td>53</td>\n",
       "      <td>0.710456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Missing Percent\n",
       "location   2458        32.949062\n",
       "keyword      53         0.710456"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of Data Missing Per Column Above 1%\n",
    "\n",
    "total = data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Missing Percent'])\n",
    "missing_data['Missing Percent'] = missing_data['Missing Percent'].apply(lambda x: x * 100)\n",
    "missing_data.loc[missing_data['Missing Percent'] > .01][:152]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "6954b8f4",
=======
   "execution_count": 9,
   "id": "79b973e3",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:07.763977Z",
     "start_time": "2022-07-11T22:23:07.763948Z"
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "necessary_columns = data[['clean_text', 'target']]"
=======
    "# train = data[['clean_text', 'target']][0:5595]\n",
    "# validation = data[['clean_text', 'target']][5595:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e53770a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T22:54:52.535762Z",
     "start_time": "2022-07-05T22:54:52.524770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reason allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la range canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resident ask shelter place officer evacuation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people evacuation order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get send photo smoke school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>video pick body water rescuer search hundred m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>fear miss migrant med rescuer search survivor ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>rescuer search hundred migrant mediterranean boat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>desire watch rescuer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>fear miss migrant med rescuer search survivor ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  target\n",
       "0                                  reason allah forgive       1\n",
       "1                      forest fire near la range canada       1\n",
       "2     resident ask shelter place officer evacuation ...       1\n",
       "3                    people evacuation order california       1\n",
       "4                           get send photo smoke school       1\n",
       "...                                                 ...     ...\n",
       "5625  video pick body water rescuer search hundred m...       1\n",
       "5626  fear miss migrant med rescuer search survivor ...       1\n",
       "5627  rescuer search hundred migrant mediterranean boat       1\n",
       "5628                               desire watch rescuer       0\n",
       "5629  fear miss migrant med rescuer search survivor ...       1\n",
       "\n",
       "[5595 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train"
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "79b973e3",
=======
   "execution_count": 11,
   "id": "4168c928",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:23:07.768342Z",
     "start_time": "2022-07-11T22:23:07.768321Z"
    }
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "# Creating a validation dataframe with 25%\n",
    "# values of original dataframe\n",
    "validation = necessary_columns.sample(frac = 0.25)\n",
    " \n",
    "# Creating dataframe with the 75 % remaing values\n",
    "train = necessary_columns.drop(validation.index)\n",
    " \n",
    "print(\"Validation of the given DataFrame:\")\n",
    "print(validation.info())\n",
    " \n",
    "print(\"Train set of the given DataFrame:\")\n",
    "print(train.info())"
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>channel spa dog rescuer door</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>video pick body water rescuer search hundred m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>woman gas app guide rescuer injure county</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>video pick body water rescuer search hundred m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>video pick body water rescuer search hundred m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>fall pipeline link tram update fire crew evacu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>flip bomb evacuate stay blow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>suicide bomber kill saudi security site mosque...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>giant crane hold bridge collapse nearby home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>late home raze northern california wildfire ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1865 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  target\n",
       "5630                       channel spa dog rescuer door       0\n",
       "5631  video pick body water rescuer search hundred m...       1\n",
       "5632          woman gas app guide rescuer injure county       1\n",
       "5633  video pick body water rescuer search hundred m...       1\n",
       "5634  video pick body water rescuer search hundred m...       1\n",
       "...                                                 ...     ...\n",
       "7498  fall pipeline link tram update fire crew evacu...       1\n",
       "7499                       flip bomb evacuate stay blow       1\n",
       "7500  suicide bomber kill saudi security site mosque...       1\n",
       "7501       giant crane hold bridge collapse nearby home       1\n",
       "7502  late home raze northern california wildfire ac...       1\n",
       "\n",
       "[1865 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba030694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['clean_text']]\n",
    "y = data[['target']]"
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "04ffe2cb",
=======
   "execution_count": 23,
   "id": "327e268d",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T22:24:30.023821Z",
     "start_time": "2022-07-11T22:24:30.012466Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitting the data into a train and validation\n",
    "\n",
<<<<<<< HEAD
    "X_train, X_validation, y_train, y_validation = train_test_split(data['clean_text'], \n",
    "                                                                data['target'], \n",
=======
    "X_train, X_validation, y_train, y_validation = train_test_split(X, \n",
    "                                                                y, \n",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
    "                                                                test_size = 0.25, \n",
    "                                                                shuffle = True,\n",
    "                                                                random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "id": "2626fbbf",
=======
   "execution_count": 28,
   "id": "8b317499",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T23:17:57.336800Z",
     "start_time": "2022-07-11T22:50:43.401314Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bert = SentenceTransformer('stsb-roberta-large') #1.3 gb\n",
    "\n",
    "\n",
    "# Vectorize the data\n",
    "\n",
    "X_train_vec = pd.DataFrame(np.vstack(X_train.apply(bert.encode)))\n",
    "\n",
    "\n",
    "X_validation_vec = pd.DataFrame(np.vstack(X_validation.apply(bert.encode)))\n",
    "\n",
    "# BERT doesn't have feature names\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=500, n_jobs=8)\n",
    "# model.fit(X_train_vec, y_train)\n",
    "# model.score(X_validation_vec, y_validation)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "id": "8baf3747",
=======
   "execution_count": 29,
   "id": "ab81818d",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T23:45:11.646833Z",
     "start_time": "2022-07-11T23:45:11.636023Z"
    }
   },
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5595, 1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1865, 1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5595,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1865,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
=======
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e3d8a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T22:55:12.571346Z",
     "start_time": "2022-07-05T22:55:10.691094Z"
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
    }
   ],
   "source": [
    "display(X_train_vec.shape)\n",
    "display(X_validation_vec.shape)\n",
    "display(y_train.shape)\n",
    "y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "id": "6f17223e",
=======
   "execution_count": 31,
   "id": "e5bf808b",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T00:04:21.550998Z",
     "start_time": "2022-07-12T00:04:21.546495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
=======
       "TensorShape([1, 8, 1024])"
      ]
     },
     "execution_count": 31,
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "id": "66ae06a9",
=======
   "execution_count": 32,
   "id": "73cbb4c7",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T00:07:29.660137Z",
     "start_time": "2022-07-12T00:07:23.695881Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_vec.to_csv('X_train_vec.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "c6eeca94",
=======
   "execution_count": 42,
   "id": "49e5ef66",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T00:07:29.831764Z",
     "start_time": "2022-07-12T00:07:29.831734Z"
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "X_validation_vec.to_csv('X_validation_vec.csv', index = False)"
=======
    "list_train = [X_train[i:i+100] for i in range(0,X_train.shape[0],100)] \n",
    "list_validation = [X_validation[i:i+100] for i in range(0,X_validation.shape[0],100)]"
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "5fdfc4e4",
=======
   "execution_count": 44,
   "id": "5b7262ac",
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T00:07:29.836717Z",
     "start_time": "2022-07-12T00:07:29.836673Z"
    }
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "y_train.to_csv('y_train.csv', index = False)"
=======
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'bilm/CNN/Conv2D_4' defined at (most recent call last):\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\NEL-JI~1\\AppData\\Local\\Temp/ipykernel_22264/646319018.py\", line 1, in <module>\n      elmo = hub.load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\", line 106, in load\n      obj = tf.compat.v1.saved_model.load_v2(module_path, tags=tags)\nNode: 'bilm/CNN/Conv2D_4'\nOOM when allocating tensor with shape[5595,256,17,46] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bilm/CNN/Conv2D_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_pruned_12319]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NEL-JI~1\\AppData\\Local\\Temp/ipykernel_22264/2208363120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract ELMo embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0melmo_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0melmo_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0melmo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0melmo_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_validation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NEL-JI~1\\AppData\\Local\\Temp/ipykernel_22264/2208363120.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract ELMo embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0melmo_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0melmo_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0melmo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0melmo_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_validation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NEL-JI~1\\AppData\\Local\\Temp/ipykernel_22264/1558920290.py\u001b[0m in \u001b[0;36melmo_vectors\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0melmo_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melmo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"elmo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1600\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m     \"\"\"\n\u001b[1;32m-> 1602\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m    241\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m       return super(WrappedFunction, self)._call_impl(\n\u001b[0m\u001b[0;32m    244\u001b[0m           args, kwargs, cancellation_manager)\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1618\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_with_flat_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                         \u001b[1;34mf\"#{i}(zero-based) to be a Tensor; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                         f\"got {type(arg).__name__} ({arg}).\")\n\u001b[1;32m-> 1669\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_with_structured_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'bilm/CNN/Conv2D_4' defined at (most recent call last):\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\NEL-JI~1\\AppData\\Local\\Temp/ipykernel_22264/646319018.py\", line 1, in <module>\n      elmo = hub.load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]\n    File \"C:\\Users\\Nel-Jiren\\anaconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\", line 106, in load\n      obj = tf.compat.v1.saved_model.load_v2(module_path, tags=tags)\nNode: 'bilm/CNN/Conv2D_4'\nOOM when allocating tensor with shape[5595,256,17,46] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bilm/CNN/Conv2D_4}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_pruned_12319]"
     ]
    }
   ],
   "source": [
    "# Extract ELMo embeddings \n",
    "elmo_train = [elmo_vectors(X_train['clean_text']) for x in list_train] \n",
    "elmo_validation = [elmo_vectors(X_validation['clean_text']) for x in list_validation]"
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f9470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T00:07:29.841813Z",
     "start_time": "2022-07-12T00:07:29.841757Z"
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "y_validation.to_csv('y_validation.csv', index = False)"
=======
    "# Once we have all the vectors, we can concatenate them back to a single array:\n",
    "\n",
    "elmo_X_train = np.concatenate(elmo_train, axis = 0) \n",
    "elmo_X_validation = np.concatenate(elmo_validation, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d96e8c",
   "metadata": {},
   "source": [
    "# We still need to append the target column from the both of the train and validation dataframes \n",
    "\n",
    "\n",
    "# Both the elmo_X_train and elmo_X_validation need their target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afccd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these arrays becuase of the long time it took to get the ELMo vectors \n",
    "# Saving them as pickle files\n",
    "\n",
    "\n",
    "# # save elmo_train_new\n",
    "# pickle_out = open(\"elmo_X_train.pickle\",\"wb\")\n",
    "# pickle.dump(elmo_X_train, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# # save elmo_test_new\n",
    "# pickle_out = open(\"elmo_X_validation.pickle\",\"wb\")\n",
    "# pickle.dump(elmo_X_validation, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90966ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can use the following code to load them back\n",
    "\n",
    "# # load elmo_train_new\n",
    "# pickle_in = open(\"elmo_X_train.pickle\", \"rb\")\n",
    "# elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "# # load elmo_train_new\n",
    "# pickle_in = open(\"elmo_X_validation.pickle\", \"rb\")\n",
    "# elmo_test_new = pickle.load(pickle_in)"
>>>>>>> 5790ec5c264954e32ec8e16b45af8cacf1a3feae
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
